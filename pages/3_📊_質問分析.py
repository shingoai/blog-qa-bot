import streamlit as st
import pandas as pd
from components.question_logger import QuestionLogger
from utils.auth import check_password
from datetime import datetime, timedelta
import json
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
import re

st.set_page_config(
    page_title="è³ªå•åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

if not check_password(require_admin=True):
    st.stop()

st.title("ğŸ“Š è³ªå•åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ç”Ÿå¾’ã‹ã‚‰ã®è³ªå•ã‚’åˆ†æã—ã€æ•™ææ”¹å–„ã«æ´»ç”¨ã—ã¾ã™ã€‚")

@st.cache_resource
def init_logger():
    return QuestionLogger()

logger = init_logger()

# ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ç”¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
CATEGORY_KEYWORDS = {
    "WordPress": ["wordpress", "wp", "ãƒ—ãƒ©ã‚°ã‚¤ãƒ³", "ãƒ†ãƒ¼ãƒ"],
    "SEO": ["seo", "æ¤œç´¢", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "é †ä½", "google"],
    "ã‚¿ã‚¤ãƒˆãƒ«": ["ã‚¿ã‚¤ãƒˆãƒ«", "è¦‹å‡ºã—", "é¡Œå", "ä»¶å"],
    "è¨˜äº‹ä½œæˆ": ["è¨˜äº‹", "åŸ·ç­†", "æ–‡ç« ", "ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°", "æ›¸ãæ–¹"],
    "ãƒ–ãƒ­ã‚°é‹å–¶": ["é‹å–¶", "åç›Š", "ã‚¢ã‚¯ã‚»ã‚¹", "pv", "åºƒå‘Š"],
    "æŠ€è¡“çš„ãªè³ªå•": ["ã‚¨ãƒ©ãƒ¼", "è¨­å®š", "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«", "ãƒã‚°", "ä¸å…·åˆ"],
    "ãã®ä»–": []
}

def categorize_question(question):
    """è³ªå•ã‚’ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
    question_lower = question.lower()
    for category, keywords in CATEGORY_KEYWORDS.items():
        if category == "ãã®ä»–":
            continue
        for keyword in keywords:
            if keyword in question_lower:
                return category
    return "ãã®ä»–"

def extract_keywords(text, top_n=10):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    # æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
    words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¥]+', text)
    # 2æ–‡å­—ä»¥ä¸Šã®å˜èªã®ã¿
    words = [w for w in words if len(w) >= 2]
    # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    stop_words = ['ã§ã™', 'ã¾ã™', 'ã“ã¨', 'ã‚‚ã®', 'ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ', 'ã¨ã„ã†', 'ã‚ˆã†ãª']
    words = [w for w in words if w not in stop_words]
    
    word_count = Counter(words)
    return word_count.most_common(top_n)

tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ˆ çµ±è¨ˆæ¦‚è¦", "ğŸ“Š è©³ç´°åˆ†æ", "â“ ã‚ˆãã‚ã‚‹è³ªå•", 
    "ğŸ” è³ªå•æ¤œç´¢", "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†æ", "ğŸ“¥ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
])

with tab1:
    st.header("çµ±è¨ˆæ¦‚è¦")
    
    stats = logger.get_stats()
    all_logs = logger.get_all_logs()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·è³ªå•æ•°", stats["total_questions"])
    
    with col2:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè³ªå•", stats["unique_questions"])
    
    with col3:
        st.metric("å¹³å‡è³ªå•/æ—¥", stats["avg_questions_per_day"])
    
    with col4:
        response_rate = (stats["unique_questions"] / stats["total_questions"] * 100) if stats["total_questions"] > 0 else 0
        st.metric("å›ç­”ã‚«ãƒãƒ¼ç‡", f"{response_rate:.1f}%")
    
    st.divider()
    
    # æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
    if all_logs:
        st.subheader("ğŸ“… è³ªå•æ•°ã®æ¨ç§»")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        df = pd.DataFrame(all_logs)
        df['date'] = pd.to_datetime(df['timestamp']).dt.date
        daily_counts = df.groupby('date').size().reset_index(name='count')
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig = px.line(daily_counts, x='date', y='count', 
                     title='æ—¥åˆ¥è³ªå•æ•°',
                     labels={'date': 'æ—¥ä»˜', 'count': 'è³ªå•æ•°'})
        fig.update_traces(mode='lines+markers')
        st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    st.subheader("ğŸ• æœ€è¿‘ã®è³ªå•ï¼ˆç›´è¿‘10ä»¶ï¼‰")
    recent_logs = logger.get_recent_logs(10)
    
    if recent_logs:
        for log in recent_logs:
            category = categorize_question(log['question'])
            with st.expander(f"[{category}] {log['question'][:50]}..."):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write("**è³ªå•:**", log['question'])
                    st.write("**å›ç­”:**", log['answer'][:200] + "...")
                with col2:
                    st.caption(f"ğŸ“… {log['timestamp'][:19]}")
                    st.caption(f"ğŸ·ï¸ {category}")
    else:
        st.info("ã¾ã è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab2:
    st.header("ğŸ“Š è©³ç´°åˆ†æ")
    
    if all_logs:
        # æ™‚é–“å¸¯åˆ¥åˆ†æ
        st.subheader("â° æ™‚é–“å¸¯åˆ¥è³ªå•æ•°")
        df = pd.DataFrame(all_logs)
        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
        hourly_counts = df.groupby('hour').size().reset_index(name='count')
        
        fig = px.bar(hourly_counts, x='hour', y='count',
                    title='æ™‚é–“å¸¯åˆ¥è³ªå•æ•°',
                    labels={'hour': 'æ™‚é–“', 'count': 'è³ªå•æ•°'})
        st.plotly_chart(fig, use_container_width=True)
        
        # æ›œæ—¥åˆ¥åˆ†æ
        st.subheader("ğŸ“… æ›œæ—¥åˆ¥è³ªå•æ•°")
        df['weekday'] = pd.to_datetime(df['timestamp']).dt.day_name()
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekday_counts = df.groupby('weekday').size().reindex(weekday_order, fill_value=0).reset_index(name='count')
        weekday_counts['weekday_jp'] = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        
        fig = px.bar(weekday_counts, x='weekday_jp', y='count',
                    title='æ›œæ—¥åˆ¥è³ªå•æ•°',
                    labels={'weekday_jp': 'æ›œæ—¥', 'count': 'è³ªå•æ•°'})
        st.plotly_chart(fig, use_container_width=True)
        
        # è³ªå•ã®é•·ã•åˆ†æ
        st.subheader("ğŸ“ è³ªå•ã®é•·ã•åˆ†å¸ƒ")
        df['question_length'] = df['question'].str.len()
        
        fig = px.histogram(df, x='question_length', nbins=20,
                          title='è³ªå•ã®æ–‡å­—æ•°åˆ†å¸ƒ',
                          labels={'question_length': 'æ–‡å­—æ•°', 'count': 'è³ªå•æ•°'})
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab3:
    st.header("â“ ã‚ˆãã‚ã‚‹è³ªå•ã®å‚¾å‘")
    
    if all_logs:
        # è³ªå•ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆé¡ä¼¼è³ªå•ã‚’ã¾ã¨ã‚ã‚‹ï¼‰
        question_groups = {}
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        for log in all_logs:
            question = log['question']
            # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            keywords = extract_keywords(question, 3)
            if keywords:
                main_keyword = keywords[0][0]  # æœ€é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                if main_keyword not in question_groups:
                    question_groups[main_keyword] = {
                        'questions': [],
                        'count': 0,
                        'category': categorize_question(question)
                    }
                question_groups[main_keyword]['questions'].append(question)
                question_groups[main_keyword]['count'] += 1
        
        # é »åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_groups = sorted(question_groups.items(), key=lambda x: x[1]['count'], reverse=True)
        
        if sorted_groups:
            # ä¸Šä½ãƒˆãƒ”ãƒƒã‚¯ã®å††ã‚°ãƒ©ãƒ•
            top_topics = sorted_groups[:10]
            df_topics = pd.DataFrame([
                {'topic': topic, 'count': data['count']} 
                for topic, data in top_topics
            ])
            
            fig = px.pie(df_topics, values='count', names='topic',
                        title='ã‚ˆãè³ªå•ã•ã‚Œã‚‹ãƒˆãƒ”ãƒƒã‚¯ TOP 10')
            st.plotly_chart(fig, use_container_width=True)
            
            st.divider()
            
            # ãƒˆãƒ”ãƒƒã‚¯åˆ¥è©³ç´°
            st.subheader("ğŸ“Œ ã‚ˆãè³ªå•ã•ã‚Œã‚‹ãƒˆãƒ”ãƒƒã‚¯")
            
            for i, (topic, data) in enumerate(top_topics[:10], 1):
                with st.expander(f"{i}. ã€Œ{topic}ã€ã«é–¢ã™ã‚‹è³ªå• ({data['count']}ä»¶)"):
                    st.write(f"**ã‚«ãƒ†ã‚´ãƒª:** {data['category']}")
                    st.write(f"**è³ªå•æ•°:** {data['count']}ä»¶")
                    st.write("**ä»£è¡¨çš„ãªè³ªå•:**")
                    
                    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè³ªå•ã‚’è¡¨ç¤ºï¼ˆæœ€å¤§5ä»¶ï¼‰
                    unique_questions = list(set(data['questions']))[:5]
                    for q in unique_questions:
                        st.write(f"â€¢ {q[:100]}...")
                    
                    # ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã®å›ç­”æ”¹å–„ææ¡ˆ
                    if data['count'] >= 3:
                        st.info(f"ğŸ’¡ ã€Œ{topic}ã€ã«é–¢ã™ã‚‹è³ªå•ãŒå¤šã„ãŸã‚ã€ã“ã®å†…å®¹ã‚’æ•™æã§è©³ã—ãèª¬æ˜ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        
        # å…¨ä½“çš„ãªå‚¾å‘åˆ†æ
        st.divider()
        st.subheader("ğŸ“Š è³ªå•å‚¾å‘ã®åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å˜ç™ºè³ªå• vs ç¹°ã‚Šè¿”ã—è³ªå•
            unique_questions = set([log['question'] for log in all_logs])
            repeat_rate = (1 - len(unique_questions) / len(all_logs)) * 100 if all_logs else 0
            
            st.metric("ç¹°ã‚Šè¿”ã—è³ªå•ç‡", f"{repeat_rate:.1f}%", 
                     help="åŒã˜è³ªå•ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹å‰²åˆã€‚é«˜ã„å ´åˆã¯æ•™æã®æ”¹å–„ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
        
        with col2:
            # å¹³å‡è³ªå•é•·
            avg_length = sum(len(log['question']) for log in all_logs) / len(all_logs) if all_logs else 0
            st.metric("å¹³å‡è³ªå•æ–‡å­—æ•°", f"{avg_length:.0f}æ–‡å­—",
                     help="è³ªå•ã®è¤‡é›‘ã•ã®æŒ‡æ¨™ã€‚é•·ã„è³ªå•ãŒå¤šã„å ´åˆã¯ã€ã‚ˆã‚Šè©³ç´°ãªèª¬æ˜ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
        
        # æ”¹å–„ææ¡ˆ
        st.divider()
        st.subheader("ğŸ’¡ æ•™ææ”¹å–„ã®ææ¡ˆ")
        
        suggestions = []
        
        # ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã®ææ¡ˆ
        for topic, data in sorted_groups[:5]:
            if data['count'] >= 3:
                suggestions.append(f"â€¢ ã€Œ{topic}ã€ã«ã¤ã„ã¦å°‚ç”¨ã®ãƒ¬ãƒƒã‚¹ãƒ³ã‚’è¿½åŠ ")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ææ¡ˆ
        categories = [categorize_question(log['question']) for log in all_logs]
        category_counts = Counter(categories)
        for category, count in category_counts.most_common(3):
            if count >= 5:
                suggestions.append(f"â€¢ {category}ã‚«ãƒ†ã‚´ãƒªã®å†…å®¹ã‚’å……å®Ÿ")
        
        if suggestions:
            for suggestion in suggestions[:5]:
                st.write(suggestion)
        else:
            st.info("ç¾åœ¨ã®ã¨ã“ã‚ã€ç‰¹ã«æ”¹å–„ãŒå¿…è¦ãªç®‡æ‰€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab4:
    st.header("ğŸ” è³ªå•æ¤œç´¢")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        search_keyword = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", placeholder="ä¾‹: WordPress, ã‚¿ã‚¤ãƒˆãƒ«, SEO")
    with col2:
        search_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿", ["ã™ã¹ã¦"] + list(CATEGORY_KEYWORDS.keys()))
    
    if search_keyword or search_category != "ã™ã¹ã¦":
        results = logger.search_logs(search_keyword) if search_keyword else logger.get_all_logs()
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿
        if search_category != "ã™ã¹ã¦":
            results = [log for log in results if categorize_question(log['question']) == search_category]
        
        if results:
            st.success(f"{len(results)}ä»¶ã®è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
            items_per_page = 10
            total_pages = (len(results) - 1) // items_per_page + 1
            page = st.number_input("ãƒšãƒ¼ã‚¸", min_value=1, max_value=total_pages, value=1)
            
            start_idx = (page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, len(results))
            
            for log in results[start_idx:end_idx]:
                category = categorize_question(log['question'])
                with st.expander(f"[{category}] {log['question'][:50]}..."):
                    st.write("**è³ªå•:**", log['question'])
                    st.write("**å›ç­”:**", log['answer'])
                    st.caption(f"ğŸ“… {log['timestamp'][:19]}")
        else:
            st.warning("è©²å½“ã™ã‚‹è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

with tab5:
    st.header("ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†æ")
    
    if all_logs:
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        categories = [categorize_question(log['question']) for log in all_logs]
        category_counts = Counter(categories)
        
        # å††ã‚°ãƒ©ãƒ•
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥è³ªå•å‰²åˆ")
        df_cat = pd.DataFrame(category_counts.items(), columns=['category', 'count'])
        fig = px.pie(df_cat, values='count', names='category',
                    title='ã‚«ãƒ†ã‚´ãƒªåˆ¥è³ªå•ã®å‰²åˆ')
        st.plotly_chart(fig, use_container_width=True)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°")
        for category, count in category_counts.most_common():
            with st.expander(f"{category} ({count}ä»¶)"):
                category_logs = [log for log in all_logs if categorize_question(log['question']) == category]
                
                # ã“ã®ã‚«ãƒ†ã‚´ãƒªã®æœ€é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                all_text = " ".join([log['question'] for log in category_logs])
                keywords = extract_keywords(all_text, 5)
                
                if keywords:
                    st.write("**é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:**")
                    keyword_str = ", ".join([f"{word} ({count}å›)" for word, count in keywords])
                    st.write(keyword_str)
                
                st.write("**æœ€è¿‘ã®è³ªå•:**")
                for log in category_logs[:3]:
                    st.write(f"â€¢ {log['question'][:100]}...")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        st.divider()
        st.subheader("ğŸ”¤ å…¨ä½“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")
        all_questions = " ".join([log['question'] for log in all_logs])
        top_keywords = extract_keywords(all_questions, 20)
        
        if top_keywords:
            df_keywords = pd.DataFrame(top_keywords, columns=['keyword', 'count'])
            fig = px.bar(df_keywords.head(10), x='count', y='keyword', orientation='h',
                        title='é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP 10',
                        labels={'keyword': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'count': 'å‡ºç¾å›æ•°'})
            fig.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab6:
    st.header("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“¥ CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", type="primary", use_container_width=True):
            filename = logger.export_to_csv()
            if filename:
                with open(filename, 'r', encoding='utf-8') as f:
                    csv_data = f.read()
                st.download_button(
                    label="ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_data,
                    file_name=f"question_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
                st.success("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            else:
                st.warning("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    with col2:
        if st.button("ğŸ“¥ JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", type="primary", use_container_width=True):
            logs = logger.get_all_logs()
            if logs:
                json_data = json.dumps(logs, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=json_data,
                    file_name=f"question_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
                st.success("JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            else:
                st.warning("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    with col3:
        if st.button("ğŸ“¥ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", type="primary", use_container_width=True):
            if all_logs:
                # åˆ†æãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
                report = f"""# è³ªå•åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}

## çµ±è¨ˆæ¦‚è¦
- ç·è³ªå•æ•°: {stats['total_questions']}ä»¶
- ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè³ªå•æ•°: {stats['unique_questions']}ä»¶
- 1æ—¥ã‚ãŸã‚Šã®å¹³å‡è³ªå•æ•°: {stats['avg_questions_per_day']}ä»¶

## ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
"""
                categories = [categorize_question(log['question']) for log in all_logs]
                category_counts = Counter(categories)
                for cat, count in category_counts.most_common():
                    report += f"- {cat}: {count}ä»¶ ({count/len(all_logs)*100:.1f}%)\n"
                
                report += "\n## é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP 10\n"
                all_questions = " ".join([log['question'] for log in all_logs])
                top_keywords = extract_keywords(all_questions, 10)
                for keyword, count in top_keywords:
                    report += f"- {keyword}: {count}å›\n"
                
                st.download_button(
                    label="ğŸ’¾ åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=report,
                    file_name=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown"
                )
                st.success("åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
            else:
                st.warning("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

st.sidebar.info("""
**ğŸ’¡ åˆ†æã®ãƒã‚¤ãƒ³ãƒˆ:**

1. **ã‚«ãƒ†ã‚´ãƒªåˆ†æ**: è³ªå•ã®å‚¾å‘ã‚’æŠŠæ¡
2. **æ™‚ç³»åˆ—åˆ†æ**: è³ªå•ãŒå¤šã„æ™‚é–“å¸¯ã‚’ç‰¹å®š
3. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ**: æ³¨ç›®ãƒˆãƒ”ãƒƒã‚¯ã‚’ç™ºè¦‹
4. **é »å‡ºè³ªå•**: æ•™ææ”¹å–„ã®ãƒ’ãƒ³ãƒˆ

å®šæœŸçš„ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ã€æ•™ææ”¹å–„ã«æ´»ç”¨ã—ã¾ã—ã‚‡ã†ï¼
""")